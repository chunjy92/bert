{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.extend(['..'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/b/jchun/Documents/Envs/Lycastus-Py3/lib/python35.zip',\n",
       " '/home/b/jchun/Documents/Envs/Lycastus-Py3/lib/python3.5',\n",
       " '/home/b/jchun/Documents/Envs/Lycastus-Py3/lib/python3.5/plat-linux',\n",
       " '/home/b/jchun/Documents/Envs/Lycastus-Py3/lib/python3.5/lib-dynload',\n",
       " '/usr/local/lib/python3.5',\n",
       " '/usr/local/lib/python3.5/plat-linux',\n",
       " '',\n",
       " '/home/b/jchun/Documents/Envs/Lycastus-Py3/lib/python3.5/site-packages',\n",
       " '/home/b/jchun/Documents/Envs/Lycastus-Py3/lib/python3.5/site-packages/IPython/extensions',\n",
       " '/home/b/jchun/.ipython',\n",
       " '..']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import drs\n",
    "import modeling\n",
    "from run_classifier import convert_single_example, model_fn_builder, InputExample\n",
    "import tokenization\n",
    "import attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.app.flags.DEFINE_string('f', '', 'kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flags\n",
    "model_dir  = \"../drs/output_implicit_2\"\n",
    "label_list = drs.get_senses_with_degree(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert paths\n",
    "bert_config_file = \"../uncased_L-12_H-768_A-12/bert_config.json\"\n",
    "bert_init_ckpt   = \"../uncased_L-12_H-768_A-12/bert_model.ckpt\"\n",
    "bert_vocab_file  = \"../uncased_L-12_H-768_A-12/vocab.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment settings\n",
    "seq_length = 128\n",
    "num_hidden_layers=12\n",
    "num_attention_heads=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "tokenizer  = tokenization.FullTokenizer(\n",
    "      vocab_file=bert_vocab_file,\n",
    "      do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_config = modeling.BertConfig.from_json_file(bert_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Contingency.Condition',\n",
       " 'Expansion.Alternative',\n",
       " 'Temporal.Asynchronous',\n",
       " 'Comparison.Contrast',\n",
       " 'Expansion.Instantiation',\n",
       " 'Expansion.Exception',\n",
       " 'Comparison.Concession',\n",
       " 'Expansion.Conjunction',\n",
       " 'Comparison',\n",
       " 'Temporal',\n",
       " 'Expansion.Restatement',\n",
       " 'EntRel',\n",
       " 'Expansion',\n",
       " 'Contingency',\n",
       " 'Temporal.Synchrony',\n",
       " 'Contingency.Cause']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fn = model_fn_builder(\n",
    "      bert_config=bert_config,\n",
    "      num_labels=len(label_list),\n",
    "      init_checkpoint=bert_init_ckpt,\n",
    "      use_one_hot_embeddings=False,\n",
    "      learning_rate=None,\n",
    "      num_train_steps=None,\n",
    "      num_warmup_steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_config = tf.contrib.tpu.RunConfig(\n",
    "      cluster=None,\n",
    "      model_dir=model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fc5c70db598>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using config: {'_device_fn': None, '_task_type': 'worker', '_task_id': 0, '_experimental_distribute': None, '_protocol': None, '_keep_checkpoint_max': 5, '_save_summary_steps': 100, '_tf_random_seed': None, '_evaluation_master': '', '_num_worker_replicas': 1, '_cluster': None, '_tpu_config': TPUConfig(iterations_per_loop=2, num_shards=None, num_cores_per_replica=None, per_host_input_for_training=2, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_log_step_count_steps': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_save_checkpoints_steps': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc66b0c12e8>, '_eval_distribute': None, '_model_dir': '../drs/output_implicit_2', '_keep_checkpoint_every_n_hours': 10000, '_num_ps_replicas': 0, '_save_checkpoints_secs': 600, '_train_distribute': None, '_is_chief': True, '_master': '', '_service': None, '_global_id_in_cluster': 0}\n",
      "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
      "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n"
     ]
    }
   ],
   "source": [
    "model = tf.contrib.tpu.TPUEstimator(\n",
    "    use_tpu=False,\n",
    "    model_fn=model_fn,\n",
    "    config=run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bert/embeddings/LayerNorm/beta',\n",
       " 'bert/embeddings/LayerNorm/beta/adam_m',\n",
       " 'bert/embeddings/LayerNorm/beta/adam_v',\n",
       " 'bert/embeddings/LayerNorm/gamma',\n",
       " 'bert/embeddings/LayerNorm/gamma/adam_m',\n",
       " 'bert/embeddings/LayerNorm/gamma/adam_v',\n",
       " 'bert/embeddings/position_embeddings',\n",
       " 'bert/embeddings/position_embeddings/adam_m',\n",
       " 'bert/embeddings/position_embeddings/adam_v',\n",
       " 'bert/embeddings/token_type_embeddings',\n",
       " 'bert/embeddings/token_type_embeddings/adam_m',\n",
       " 'bert/embeddings/token_type_embeddings/adam_v',\n",
       " 'bert/embeddings/word_embeddings',\n",
       " 'bert/embeddings/word_embeddings/adam_m',\n",
       " 'bert/embeddings/word_embeddings/adam_v',\n",
       " 'bert/encoder/layer_0/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_0/attention/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_0/attention/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_0/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_0/attention/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_0/attention/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_0/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_0/attention/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_0/attention/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_0/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_0/attention/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_0/attention/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_0/attention/self/key/bias',\n",
       " 'bert/encoder/layer_0/attention/self/key/bias/adam_m',\n",
       " 'bert/encoder/layer_0/attention/self/key/bias/adam_v',\n",
       " 'bert/encoder/layer_0/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_0/attention/self/key/kernel/adam_m',\n",
       " 'bert/encoder/layer_0/attention/self/key/kernel/adam_v',\n",
       " 'bert/encoder/layer_0/attention/self/query/bias',\n",
       " 'bert/encoder/layer_0/attention/self/query/bias/adam_m',\n",
       " 'bert/encoder/layer_0/attention/self/query/bias/adam_v',\n",
       " 'bert/encoder/layer_0/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_0/attention/self/query/kernel/adam_m',\n",
       " 'bert/encoder/layer_0/attention/self/query/kernel/adam_v',\n",
       " 'bert/encoder/layer_0/attention/self/value/bias',\n",
       " 'bert/encoder/layer_0/attention/self/value/bias/adam_m',\n",
       " 'bert/encoder/layer_0/attention/self/value/bias/adam_v',\n",
       " 'bert/encoder/layer_0/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_0/attention/self/value/kernel/adam_m',\n",
       " 'bert/encoder/layer_0/attention/self/value/kernel/adam_v',\n",
       " 'bert/encoder/layer_0/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_0/intermediate/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_0/intermediate/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_0/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_0/intermediate/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_0/intermediate/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_0/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_0/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_0/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_0/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_0/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_0/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_0/output/dense/bias',\n",
       " 'bert/encoder/layer_0/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_0/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_0/output/dense/kernel',\n",
       " 'bert/encoder/layer_0/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_0/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_1/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_1/attention/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_1/attention/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_1/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_1/attention/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_1/attention/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_1/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_1/attention/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_1/attention/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_1/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_1/attention/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_1/attention/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_1/attention/self/key/bias',\n",
       " 'bert/encoder/layer_1/attention/self/key/bias/adam_m',\n",
       " 'bert/encoder/layer_1/attention/self/key/bias/adam_v',\n",
       " 'bert/encoder/layer_1/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_1/attention/self/key/kernel/adam_m',\n",
       " 'bert/encoder/layer_1/attention/self/key/kernel/adam_v',\n",
       " 'bert/encoder/layer_1/attention/self/query/bias',\n",
       " 'bert/encoder/layer_1/attention/self/query/bias/adam_m',\n",
       " 'bert/encoder/layer_1/attention/self/query/bias/adam_v',\n",
       " 'bert/encoder/layer_1/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_1/attention/self/query/kernel/adam_m',\n",
       " 'bert/encoder/layer_1/attention/self/query/kernel/adam_v',\n",
       " 'bert/encoder/layer_1/attention/self/value/bias',\n",
       " 'bert/encoder/layer_1/attention/self/value/bias/adam_m',\n",
       " 'bert/encoder/layer_1/attention/self/value/bias/adam_v',\n",
       " 'bert/encoder/layer_1/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_1/attention/self/value/kernel/adam_m',\n",
       " 'bert/encoder/layer_1/attention/self/value/kernel/adam_v',\n",
       " 'bert/encoder/layer_1/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_1/intermediate/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_1/intermediate/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_1/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_1/intermediate/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_1/intermediate/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_1/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_1/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_1/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_1/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_1/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_1/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_1/output/dense/bias',\n",
       " 'bert/encoder/layer_1/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_1/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_1/output/dense/kernel',\n",
       " 'bert/encoder/layer_1/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_1/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_10/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_10/attention/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_10/attention/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_10/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_10/attention/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_10/attention/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_10/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_10/attention/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_10/attention/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_10/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_10/attention/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_10/attention/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_10/attention/self/key/bias',\n",
       " 'bert/encoder/layer_10/attention/self/key/bias/adam_m',\n",
       " 'bert/encoder/layer_10/attention/self/key/bias/adam_v',\n",
       " 'bert/encoder/layer_10/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_10/attention/self/key/kernel/adam_m',\n",
       " 'bert/encoder/layer_10/attention/self/key/kernel/adam_v',\n",
       " 'bert/encoder/layer_10/attention/self/query/bias',\n",
       " 'bert/encoder/layer_10/attention/self/query/bias/adam_m',\n",
       " 'bert/encoder/layer_10/attention/self/query/bias/adam_v',\n",
       " 'bert/encoder/layer_10/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_10/attention/self/query/kernel/adam_m',\n",
       " 'bert/encoder/layer_10/attention/self/query/kernel/adam_v',\n",
       " 'bert/encoder/layer_10/attention/self/value/bias',\n",
       " 'bert/encoder/layer_10/attention/self/value/bias/adam_m',\n",
       " 'bert/encoder/layer_10/attention/self/value/bias/adam_v',\n",
       " 'bert/encoder/layer_10/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_10/attention/self/value/kernel/adam_m',\n",
       " 'bert/encoder/layer_10/attention/self/value/kernel/adam_v',\n",
       " 'bert/encoder/layer_10/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_10/intermediate/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_10/intermediate/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_10/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_10/intermediate/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_10/intermediate/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_10/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_10/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_10/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_10/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_10/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_10/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_10/output/dense/bias',\n",
       " 'bert/encoder/layer_10/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_10/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_10/output/dense/kernel',\n",
       " 'bert/encoder/layer_10/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_10/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_11/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_11/attention/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_11/attention/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_11/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_11/attention/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_11/attention/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_11/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_11/attention/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_11/attention/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_11/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_11/attention/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_11/attention/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_11/attention/self/key/bias',\n",
       " 'bert/encoder/layer_11/attention/self/key/bias/adam_m',\n",
       " 'bert/encoder/layer_11/attention/self/key/bias/adam_v',\n",
       " 'bert/encoder/layer_11/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_11/attention/self/key/kernel/adam_m',\n",
       " 'bert/encoder/layer_11/attention/self/key/kernel/adam_v',\n",
       " 'bert/encoder/layer_11/attention/self/query/bias',\n",
       " 'bert/encoder/layer_11/attention/self/query/bias/adam_m',\n",
       " 'bert/encoder/layer_11/attention/self/query/bias/adam_v',\n",
       " 'bert/encoder/layer_11/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_11/attention/self/query/kernel/adam_m',\n",
       " 'bert/encoder/layer_11/attention/self/query/kernel/adam_v',\n",
       " 'bert/encoder/layer_11/attention/self/value/bias',\n",
       " 'bert/encoder/layer_11/attention/self/value/bias/adam_m',\n",
       " 'bert/encoder/layer_11/attention/self/value/bias/adam_v',\n",
       " 'bert/encoder/layer_11/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_11/attention/self/value/kernel/adam_m',\n",
       " 'bert/encoder/layer_11/attention/self/value/kernel/adam_v',\n",
       " 'bert/encoder/layer_11/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_11/intermediate/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_11/intermediate/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_11/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_11/intermediate/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_11/intermediate/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_11/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_11/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_11/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_11/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_11/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_11/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_11/output/dense/bias',\n",
       " 'bert/encoder/layer_11/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_11/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_11/output/dense/kernel',\n",
       " 'bert/encoder/layer_11/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_11/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_2/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_2/attention/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_2/attention/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_2/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_2/attention/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_2/attention/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_2/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_2/attention/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_2/attention/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_2/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_2/attention/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_2/attention/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_2/attention/self/key/bias',\n",
       " 'bert/encoder/layer_2/attention/self/key/bias/adam_m',\n",
       " 'bert/encoder/layer_2/attention/self/key/bias/adam_v',\n",
       " 'bert/encoder/layer_2/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_2/attention/self/key/kernel/adam_m',\n",
       " 'bert/encoder/layer_2/attention/self/key/kernel/adam_v',\n",
       " 'bert/encoder/layer_2/attention/self/query/bias',\n",
       " 'bert/encoder/layer_2/attention/self/query/bias/adam_m',\n",
       " 'bert/encoder/layer_2/attention/self/query/bias/adam_v',\n",
       " 'bert/encoder/layer_2/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_2/attention/self/query/kernel/adam_m',\n",
       " 'bert/encoder/layer_2/attention/self/query/kernel/adam_v',\n",
       " 'bert/encoder/layer_2/attention/self/value/bias',\n",
       " 'bert/encoder/layer_2/attention/self/value/bias/adam_m',\n",
       " 'bert/encoder/layer_2/attention/self/value/bias/adam_v',\n",
       " 'bert/encoder/layer_2/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_2/attention/self/value/kernel/adam_m',\n",
       " 'bert/encoder/layer_2/attention/self/value/kernel/adam_v',\n",
       " 'bert/encoder/layer_2/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_2/intermediate/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_2/intermediate/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_2/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_2/intermediate/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_2/intermediate/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_2/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_2/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_2/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_2/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_2/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_2/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_2/output/dense/bias',\n",
       " 'bert/encoder/layer_2/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_2/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_2/output/dense/kernel',\n",
       " 'bert/encoder/layer_2/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_2/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_3/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_3/attention/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_3/attention/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_3/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_3/attention/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_3/attention/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_3/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_3/attention/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_3/attention/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_3/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_3/attention/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_3/attention/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_3/attention/self/key/bias',\n",
       " 'bert/encoder/layer_3/attention/self/key/bias/adam_m',\n",
       " 'bert/encoder/layer_3/attention/self/key/bias/adam_v',\n",
       " 'bert/encoder/layer_3/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_3/attention/self/key/kernel/adam_m',\n",
       " 'bert/encoder/layer_3/attention/self/key/kernel/adam_v',\n",
       " 'bert/encoder/layer_3/attention/self/query/bias',\n",
       " 'bert/encoder/layer_3/attention/self/query/bias/adam_m',\n",
       " 'bert/encoder/layer_3/attention/self/query/bias/adam_v',\n",
       " 'bert/encoder/layer_3/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_3/attention/self/query/kernel/adam_m',\n",
       " 'bert/encoder/layer_3/attention/self/query/kernel/adam_v',\n",
       " 'bert/encoder/layer_3/attention/self/value/bias',\n",
       " 'bert/encoder/layer_3/attention/self/value/bias/adam_m',\n",
       " 'bert/encoder/layer_3/attention/self/value/bias/adam_v',\n",
       " 'bert/encoder/layer_3/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_3/attention/self/value/kernel/adam_m',\n",
       " 'bert/encoder/layer_3/attention/self/value/kernel/adam_v',\n",
       " 'bert/encoder/layer_3/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_3/intermediate/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_3/intermediate/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_3/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_3/intermediate/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_3/intermediate/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_3/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_3/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_3/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_3/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_3/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_3/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_3/output/dense/bias',\n",
       " 'bert/encoder/layer_3/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_3/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_3/output/dense/kernel',\n",
       " 'bert/encoder/layer_3/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_3/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_4/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_4/attention/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_4/attention/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_4/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_4/attention/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_4/attention/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_4/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_4/attention/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_4/attention/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_4/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_4/attention/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_4/attention/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_4/attention/self/key/bias',\n",
       " 'bert/encoder/layer_4/attention/self/key/bias/adam_m',\n",
       " 'bert/encoder/layer_4/attention/self/key/bias/adam_v',\n",
       " 'bert/encoder/layer_4/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_4/attention/self/key/kernel/adam_m',\n",
       " 'bert/encoder/layer_4/attention/self/key/kernel/adam_v',\n",
       " 'bert/encoder/layer_4/attention/self/query/bias',\n",
       " 'bert/encoder/layer_4/attention/self/query/bias/adam_m',\n",
       " 'bert/encoder/layer_4/attention/self/query/bias/adam_v',\n",
       " 'bert/encoder/layer_4/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_4/attention/self/query/kernel/adam_m',\n",
       " 'bert/encoder/layer_4/attention/self/query/kernel/adam_v',\n",
       " 'bert/encoder/layer_4/attention/self/value/bias',\n",
       " 'bert/encoder/layer_4/attention/self/value/bias/adam_m',\n",
       " 'bert/encoder/layer_4/attention/self/value/bias/adam_v',\n",
       " 'bert/encoder/layer_4/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_4/attention/self/value/kernel/adam_m',\n",
       " 'bert/encoder/layer_4/attention/self/value/kernel/adam_v',\n",
       " 'bert/encoder/layer_4/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_4/intermediate/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_4/intermediate/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_4/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_4/intermediate/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_4/intermediate/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_4/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_4/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_4/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_4/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_4/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_4/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_4/output/dense/bias',\n",
       " 'bert/encoder/layer_4/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_4/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_4/output/dense/kernel',\n",
       " 'bert/encoder/layer_4/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_4/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_5/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_5/attention/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_5/attention/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_5/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_5/attention/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_5/attention/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_5/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_5/attention/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_5/attention/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_5/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_5/attention/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_5/attention/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_5/attention/self/key/bias',\n",
       " 'bert/encoder/layer_5/attention/self/key/bias/adam_m',\n",
       " 'bert/encoder/layer_5/attention/self/key/bias/adam_v',\n",
       " 'bert/encoder/layer_5/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_5/attention/self/key/kernel/adam_m',\n",
       " 'bert/encoder/layer_5/attention/self/key/kernel/adam_v',\n",
       " 'bert/encoder/layer_5/attention/self/query/bias',\n",
       " 'bert/encoder/layer_5/attention/self/query/bias/adam_m',\n",
       " 'bert/encoder/layer_5/attention/self/query/bias/adam_v',\n",
       " 'bert/encoder/layer_5/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_5/attention/self/query/kernel/adam_m',\n",
       " 'bert/encoder/layer_5/attention/self/query/kernel/adam_v',\n",
       " 'bert/encoder/layer_5/attention/self/value/bias',\n",
       " 'bert/encoder/layer_5/attention/self/value/bias/adam_m',\n",
       " 'bert/encoder/layer_5/attention/self/value/bias/adam_v',\n",
       " 'bert/encoder/layer_5/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_5/attention/self/value/kernel/adam_m',\n",
       " 'bert/encoder/layer_5/attention/self/value/kernel/adam_v',\n",
       " 'bert/encoder/layer_5/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_5/intermediate/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_5/intermediate/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_5/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_5/intermediate/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_5/intermediate/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_5/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_5/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_5/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_5/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_5/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_5/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_5/output/dense/bias',\n",
       " 'bert/encoder/layer_5/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_5/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_5/output/dense/kernel',\n",
       " 'bert/encoder/layer_5/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_5/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_6/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_6/attention/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_6/attention/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_6/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_6/attention/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_6/attention/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_6/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_6/attention/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_6/attention/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_6/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_6/attention/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_6/attention/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_6/attention/self/key/bias',\n",
       " 'bert/encoder/layer_6/attention/self/key/bias/adam_m',\n",
       " 'bert/encoder/layer_6/attention/self/key/bias/adam_v',\n",
       " 'bert/encoder/layer_6/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_6/attention/self/key/kernel/adam_m',\n",
       " 'bert/encoder/layer_6/attention/self/key/kernel/adam_v',\n",
       " 'bert/encoder/layer_6/attention/self/query/bias',\n",
       " 'bert/encoder/layer_6/attention/self/query/bias/adam_m',\n",
       " 'bert/encoder/layer_6/attention/self/query/bias/adam_v',\n",
       " 'bert/encoder/layer_6/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_6/attention/self/query/kernel/adam_m',\n",
       " 'bert/encoder/layer_6/attention/self/query/kernel/adam_v',\n",
       " 'bert/encoder/layer_6/attention/self/value/bias',\n",
       " 'bert/encoder/layer_6/attention/self/value/bias/adam_m',\n",
       " 'bert/encoder/layer_6/attention/self/value/bias/adam_v',\n",
       " 'bert/encoder/layer_6/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_6/attention/self/value/kernel/adam_m',\n",
       " 'bert/encoder/layer_6/attention/self/value/kernel/adam_v',\n",
       " 'bert/encoder/layer_6/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_6/intermediate/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_6/intermediate/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_6/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_6/intermediate/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_6/intermediate/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_6/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_6/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_6/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_6/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_6/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_6/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_6/output/dense/bias',\n",
       " 'bert/encoder/layer_6/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_6/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_6/output/dense/kernel',\n",
       " 'bert/encoder/layer_6/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_6/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_7/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_7/attention/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_7/attention/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_7/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_7/attention/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_7/attention/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_7/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_7/attention/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_7/attention/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_7/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_7/attention/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_7/attention/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_7/attention/self/key/bias',\n",
       " 'bert/encoder/layer_7/attention/self/key/bias/adam_m',\n",
       " 'bert/encoder/layer_7/attention/self/key/bias/adam_v',\n",
       " 'bert/encoder/layer_7/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_7/attention/self/key/kernel/adam_m',\n",
       " 'bert/encoder/layer_7/attention/self/key/kernel/adam_v',\n",
       " 'bert/encoder/layer_7/attention/self/query/bias',\n",
       " 'bert/encoder/layer_7/attention/self/query/bias/adam_m',\n",
       " 'bert/encoder/layer_7/attention/self/query/bias/adam_v',\n",
       " 'bert/encoder/layer_7/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_7/attention/self/query/kernel/adam_m',\n",
       " 'bert/encoder/layer_7/attention/self/query/kernel/adam_v',\n",
       " 'bert/encoder/layer_7/attention/self/value/bias',\n",
       " 'bert/encoder/layer_7/attention/self/value/bias/adam_m',\n",
       " 'bert/encoder/layer_7/attention/self/value/bias/adam_v',\n",
       " 'bert/encoder/layer_7/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_7/attention/self/value/kernel/adam_m',\n",
       " 'bert/encoder/layer_7/attention/self/value/kernel/adam_v',\n",
       " 'bert/encoder/layer_7/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_7/intermediate/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_7/intermediate/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_7/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_7/intermediate/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_7/intermediate/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_7/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_7/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_7/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_7/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_7/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_7/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_7/output/dense/bias',\n",
       " 'bert/encoder/layer_7/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_7/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_7/output/dense/kernel',\n",
       " 'bert/encoder/layer_7/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_7/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_8/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_8/attention/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_8/attention/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_8/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_8/attention/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_8/attention/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_8/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_8/attention/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_8/attention/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_8/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_8/attention/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_8/attention/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_8/attention/self/key/bias',\n",
       " 'bert/encoder/layer_8/attention/self/key/bias/adam_m',\n",
       " 'bert/encoder/layer_8/attention/self/key/bias/adam_v',\n",
       " 'bert/encoder/layer_8/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_8/attention/self/key/kernel/adam_m',\n",
       " 'bert/encoder/layer_8/attention/self/key/kernel/adam_v',\n",
       " 'bert/encoder/layer_8/attention/self/query/bias',\n",
       " 'bert/encoder/layer_8/attention/self/query/bias/adam_m',\n",
       " 'bert/encoder/layer_8/attention/self/query/bias/adam_v',\n",
       " 'bert/encoder/layer_8/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_8/attention/self/query/kernel/adam_m',\n",
       " 'bert/encoder/layer_8/attention/self/query/kernel/adam_v',\n",
       " 'bert/encoder/layer_8/attention/self/value/bias',\n",
       " 'bert/encoder/layer_8/attention/self/value/bias/adam_m',\n",
       " 'bert/encoder/layer_8/attention/self/value/bias/adam_v',\n",
       " 'bert/encoder/layer_8/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_8/attention/self/value/kernel/adam_m',\n",
       " 'bert/encoder/layer_8/attention/self/value/kernel/adam_v',\n",
       " 'bert/encoder/layer_8/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_8/intermediate/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_8/intermediate/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_8/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_8/intermediate/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_8/intermediate/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_8/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_8/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_8/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_8/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_8/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_8/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_8/output/dense/bias',\n",
       " 'bert/encoder/layer_8/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_8/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_8/output/dense/kernel',\n",
       " 'bert/encoder/layer_8/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_8/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_9/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_9/attention/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_9/attention/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_9/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_9/attention/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_9/attention/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_9/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_9/attention/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_9/attention/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_9/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_9/attention/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_9/attention/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_9/attention/self/key/bias',\n",
       " 'bert/encoder/layer_9/attention/self/key/bias/adam_m',\n",
       " 'bert/encoder/layer_9/attention/self/key/bias/adam_v',\n",
       " 'bert/encoder/layer_9/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_9/attention/self/key/kernel/adam_m',\n",
       " 'bert/encoder/layer_9/attention/self/key/kernel/adam_v',\n",
       " 'bert/encoder/layer_9/attention/self/query/bias',\n",
       " 'bert/encoder/layer_9/attention/self/query/bias/adam_m',\n",
       " 'bert/encoder/layer_9/attention/self/query/bias/adam_v',\n",
       " 'bert/encoder/layer_9/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_9/attention/self/query/kernel/adam_m',\n",
       " 'bert/encoder/layer_9/attention/self/query/kernel/adam_v',\n",
       " 'bert/encoder/layer_9/attention/self/value/bias',\n",
       " 'bert/encoder/layer_9/attention/self/value/bias/adam_m',\n",
       " 'bert/encoder/layer_9/attention/self/value/bias/adam_v',\n",
       " 'bert/encoder/layer_9/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_9/attention/self/value/kernel/adam_m',\n",
       " 'bert/encoder/layer_9/attention/self/value/kernel/adam_v',\n",
       " 'bert/encoder/layer_9/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_9/intermediate/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_9/intermediate/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_9/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_9/intermediate/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_9/intermediate/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_9/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_9/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_9/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_9/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_9/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_9/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_9/output/dense/bias',\n",
       " 'bert/encoder/layer_9/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_9/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_9/output/dense/kernel',\n",
       " 'bert/encoder/layer_9/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_9/output/dense/kernel/adam_v',\n",
       " 'bert/pooler/dense/bias',\n",
       " 'bert/pooler/dense/bias/adam_m',\n",
       " 'bert/pooler/dense/bias/adam_v',\n",
       " 'bert/pooler/dense/kernel',\n",
       " 'bert/pooler/dense/kernel/adam_m',\n",
       " 'bert/pooler/dense/kernel/adam_v',\n",
       " 'global_step',\n",
       " 'output_bias',\n",
       " 'output_bias/adam_m',\n",
       " 'output_bias/adam_v',\n",
       " 'output_weights',\n",
       " 'output_weights/adam_m',\n",
       " 'output_weights/adam_v']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_variable_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn_builder(input_):\n",
    "    name_to_features = {\n",
    "      \"input_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "      \"input_mask\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "      \"segment_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "      \"label_ids\": tf.FixedLenFeature([], tf.int64),\n",
    "      \"is_real_example\": tf.FixedLenFeature([], tf.int64),\n",
    "      }\n",
    "    \n",
    "    def input_fn(params):\n",
    "        return tf.parse_single_example(input_, name_to_features)\n",
    "    return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = \"I went too I knew little of where, however.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_example = InputExample(guid=0, text_a=\"I went too\", text_b=\"I knew little of where, however.\", label='EntRel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: 0\n",
      "INFO:tensorflow:tokens: [CLS] i went too [SEP] i knew little of where , however . [SEP]\n",
      "INFO:tensorflow:input_ids: 101 1045 2253 2205 102 1045 2354 2210 1997 2073 1010 2174 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: EntRel (id = 11)\n"
     ]
    }
   ],
   "source": [
    "feature = convert_single_example(0, input_example, label_list, seq_length, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_int_feature(values):\n",
    "    f = tf.train.Feature(int64_list=tf.train.Int64List(value=list(values)))\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = collections.OrderedDict()\n",
    "features[\"input_ids\"] = create_int_feature(feature.input_ids)\n",
    "features[\"input_mask\"] = create_int_feature(feature.input_mask)\n",
    "features[\"segment_ids\"] = create_int_feature(feature.segment_ids)\n",
    "features[\"label_ids\"] = create_int_feature([feature.label_id])\n",
    "features[\"is_real_example\"] = create_int_feature(\n",
    "    [int(feature.is_real_example)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_example = tf.train.Example(features=tf.train.Features(feature=features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_pred_file = os.path.join(model_dir, \"viz_pred.tf_record\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.python_io.TFRecordWriter(viz_pred_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.write(tf_example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_based_input_fn_builder(input_file, seq_length, is_training,\n",
    "                                drop_remainder):\n",
    "    \"\"\"Creates an `input_fn` closure to be passed to TPUEstimator.\"\"\"\n",
    "    \n",
    "    name_to_features = {\n",
    "          \"input_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "          \"input_mask\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "          \"segment_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "          \"label_ids\": tf.FixedLenFeature([], tf.int64),\n",
    "          \"is_real_example\": tf.FixedLenFeature([], tf.int64),\n",
    "        }\n",
    "\n",
    "    def input_fn(params):\n",
    "        \"\"\"The actual input function.\"\"\"\n",
    "        d = tf.data.TFRecordDataset(input_file)\n",
    "        d = d.apply(\n",
    "            tf.contrib.data.map_and_batch(\n",
    "                lambda record: tf.parse_single_example(record, name_to_features),\n",
    "                batch_size=1,\n",
    "                drop_remainder=drop_remainder))\n",
    "        return d\n",
    "\n",
    "    return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_input_fn = file_based_input_fn_builder(\n",
    "        input_file=viz_pred_file,\n",
    "        seq_length=seq_length,\n",
    "        is_training=False,\n",
    "        drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(input_fn=predict_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-29-ad99889716a4>:20: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.map_and_batch(...)`.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running infer on CPU\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (?, 128)\n",
      "INFO:tensorflow:  name = input_mask, shape = (?, 128)\n",
      "INFO:tensorflow:  name = is_real_example, shape = (?,)\n",
      "INFO:tensorflow:  name = label_ids, shape = (?,)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (?, 128)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = output_weights:0, shape = (16, 768)\n",
      "INFO:tensorflow:  name = output_bias:0, shape = (16,)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../drs/output_implicit_2/model.ckpt-2830\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:prediction_loop marked as finished\n",
      "INFO:tensorflow:prediction_loop marked as finished\n"
     ]
    }
   ],
   "source": [
    "for (i, prediction) in enumerate(result):\n",
    "    probabilities = prediction[\"probabilities\"]\n",
    "    label = label_list[np.argmax(probabilities)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Comparison.Contrast'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bert/embeddings/LayerNorm/beta',\n",
       " 'bert/embeddings/LayerNorm/beta/adam_m',\n",
       " 'bert/embeddings/LayerNorm/beta/adam_v',\n",
       " 'bert/embeddings/LayerNorm/gamma',\n",
       " 'bert/embeddings/LayerNorm/gamma/adam_m',\n",
       " 'bert/embeddings/LayerNorm/gamma/adam_v',\n",
       " 'bert/embeddings/position_embeddings',\n",
       " 'bert/embeddings/position_embeddings/adam_m',\n",
       " 'bert/embeddings/position_embeddings/adam_v',\n",
       " 'bert/embeddings/token_type_embeddings',\n",
       " 'bert/embeddings/token_type_embeddings/adam_m',\n",
       " 'bert/embeddings/token_type_embeddings/adam_v',\n",
       " 'bert/embeddings/word_embeddings',\n",
       " 'bert/embeddings/word_embeddings/adam_m',\n",
       " 'bert/embeddings/word_embeddings/adam_v',\n",
       " 'bert/encoder/layer_0/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_0/attention/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_0/attention/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_0/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_0/attention/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_0/attention/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_0/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_0/attention/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_0/attention/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_0/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_0/attention/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_0/attention/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_0/attention/self/key/bias',\n",
       " 'bert/encoder/layer_0/attention/self/key/bias/adam_m',\n",
       " 'bert/encoder/layer_0/attention/self/key/bias/adam_v',\n",
       " 'bert/encoder/layer_0/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_0/attention/self/key/kernel/adam_m',\n",
       " 'bert/encoder/layer_0/attention/self/key/kernel/adam_v',\n",
       " 'bert/encoder/layer_0/attention/self/query/bias',\n",
       " 'bert/encoder/layer_0/attention/self/query/bias/adam_m',\n",
       " 'bert/encoder/layer_0/attention/self/query/bias/adam_v',\n",
       " 'bert/encoder/layer_0/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_0/attention/self/query/kernel/adam_m',\n",
       " 'bert/encoder/layer_0/attention/self/query/kernel/adam_v',\n",
       " 'bert/encoder/layer_0/attention/self/value/bias',\n",
       " 'bert/encoder/layer_0/attention/self/value/bias/adam_m',\n",
       " 'bert/encoder/layer_0/attention/self/value/bias/adam_v',\n",
       " 'bert/encoder/layer_0/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_0/attention/self/value/kernel/adam_m',\n",
       " 'bert/encoder/layer_0/attention/self/value/kernel/adam_v',\n",
       " 'bert/encoder/layer_0/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_0/intermediate/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_0/intermediate/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_0/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_0/intermediate/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_0/intermediate/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_0/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_0/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_0/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_0/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_0/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_0/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_0/output/dense/bias',\n",
       " 'bert/encoder/layer_0/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_0/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_0/output/dense/kernel',\n",
       " 'bert/encoder/layer_0/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_0/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_1/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_1/attention/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_1/attention/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_1/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_1/attention/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_1/attention/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_1/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_1/attention/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_1/attention/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_1/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_1/attention/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_1/attention/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_1/attention/self/key/bias',\n",
       " 'bert/encoder/layer_1/attention/self/key/bias/adam_m',\n",
       " 'bert/encoder/layer_1/attention/self/key/bias/adam_v',\n",
       " 'bert/encoder/layer_1/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_1/attention/self/key/kernel/adam_m',\n",
       " 'bert/encoder/layer_1/attention/self/key/kernel/adam_v',\n",
       " 'bert/encoder/layer_1/attention/self/query/bias',\n",
       " 'bert/encoder/layer_1/attention/self/query/bias/adam_m',\n",
       " 'bert/encoder/layer_1/attention/self/query/bias/adam_v',\n",
       " 'bert/encoder/layer_1/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_1/attention/self/query/kernel/adam_m',\n",
       " 'bert/encoder/layer_1/attention/self/query/kernel/adam_v',\n",
       " 'bert/encoder/layer_1/attention/self/value/bias',\n",
       " 'bert/encoder/layer_1/attention/self/value/bias/adam_m',\n",
       " 'bert/encoder/layer_1/attention/self/value/bias/adam_v',\n",
       " 'bert/encoder/layer_1/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_1/attention/self/value/kernel/adam_m',\n",
       " 'bert/encoder/layer_1/attention/self/value/kernel/adam_v',\n",
       " 'bert/encoder/layer_1/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_1/intermediate/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_1/intermediate/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_1/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_1/intermediate/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_1/intermediate/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_1/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_1/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_1/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_1/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_1/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_1/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_1/output/dense/bias',\n",
       " 'bert/encoder/layer_1/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_1/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_1/output/dense/kernel',\n",
       " 'bert/encoder/layer_1/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_1/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_10/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_10/attention/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_10/attention/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_10/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_10/attention/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_10/attention/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_10/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_10/attention/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_10/attention/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_10/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_10/attention/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_10/attention/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_10/attention/self/key/bias',\n",
       " 'bert/encoder/layer_10/attention/self/key/bias/adam_m',\n",
       " 'bert/encoder/layer_10/attention/self/key/bias/adam_v',\n",
       " 'bert/encoder/layer_10/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_10/attention/self/key/kernel/adam_m',\n",
       " 'bert/encoder/layer_10/attention/self/key/kernel/adam_v',\n",
       " 'bert/encoder/layer_10/attention/self/query/bias',\n",
       " 'bert/encoder/layer_10/attention/self/query/bias/adam_m',\n",
       " 'bert/encoder/layer_10/attention/self/query/bias/adam_v',\n",
       " 'bert/encoder/layer_10/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_10/attention/self/query/kernel/adam_m',\n",
       " 'bert/encoder/layer_10/attention/self/query/kernel/adam_v',\n",
       " 'bert/encoder/layer_10/attention/self/value/bias',\n",
       " 'bert/encoder/layer_10/attention/self/value/bias/adam_m',\n",
       " 'bert/encoder/layer_10/attention/self/value/bias/adam_v',\n",
       " 'bert/encoder/layer_10/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_10/attention/self/value/kernel/adam_m',\n",
       " 'bert/encoder/layer_10/attention/self/value/kernel/adam_v',\n",
       " 'bert/encoder/layer_10/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_10/intermediate/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_10/intermediate/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_10/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_10/intermediate/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_10/intermediate/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_10/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_10/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_10/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_10/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_10/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_10/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_10/output/dense/bias',\n",
       " 'bert/encoder/layer_10/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_10/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_10/output/dense/kernel',\n",
       " 'bert/encoder/layer_10/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_10/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_11/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_11/attention/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_11/attention/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_11/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_11/attention/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_11/attention/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_11/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_11/attention/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_11/attention/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_11/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_11/attention/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_11/attention/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_11/attention/self/key/bias',\n",
       " 'bert/encoder/layer_11/attention/self/key/bias/adam_m',\n",
       " 'bert/encoder/layer_11/attention/self/key/bias/adam_v',\n",
       " 'bert/encoder/layer_11/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_11/attention/self/key/kernel/adam_m',\n",
       " 'bert/encoder/layer_11/attention/self/key/kernel/adam_v',\n",
       " 'bert/encoder/layer_11/attention/self/query/bias',\n",
       " 'bert/encoder/layer_11/attention/self/query/bias/adam_m',\n",
       " 'bert/encoder/layer_11/attention/self/query/bias/adam_v',\n",
       " 'bert/encoder/layer_11/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_11/attention/self/query/kernel/adam_m',\n",
       " 'bert/encoder/layer_11/attention/self/query/kernel/adam_v',\n",
       " 'bert/encoder/layer_11/attention/self/value/bias',\n",
       " 'bert/encoder/layer_11/attention/self/value/bias/adam_m',\n",
       " 'bert/encoder/layer_11/attention/self/value/bias/adam_v',\n",
       " 'bert/encoder/layer_11/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_11/attention/self/value/kernel/adam_m',\n",
       " 'bert/encoder/layer_11/attention/self/value/kernel/adam_v',\n",
       " 'bert/encoder/layer_11/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_11/intermediate/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_11/intermediate/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_11/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_11/intermediate/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_11/intermediate/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_11/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_11/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_11/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_11/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_11/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_11/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_11/output/dense/bias',\n",
       " 'bert/encoder/layer_11/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_11/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_11/output/dense/kernel',\n",
       " 'bert/encoder/layer_11/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_11/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_2/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_2/attention/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_2/attention/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_2/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_2/attention/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_2/attention/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_2/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_2/attention/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_2/attention/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_2/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_2/attention/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_2/attention/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_2/attention/self/key/bias',\n",
       " 'bert/encoder/layer_2/attention/self/key/bias/adam_m',\n",
       " 'bert/encoder/layer_2/attention/self/key/bias/adam_v',\n",
       " 'bert/encoder/layer_2/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_2/attention/self/key/kernel/adam_m',\n",
       " 'bert/encoder/layer_2/attention/self/key/kernel/adam_v',\n",
       " 'bert/encoder/layer_2/attention/self/query/bias',\n",
       " 'bert/encoder/layer_2/attention/self/query/bias/adam_m',\n",
       " 'bert/encoder/layer_2/attention/self/query/bias/adam_v',\n",
       " 'bert/encoder/layer_2/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_2/attention/self/query/kernel/adam_m',\n",
       " 'bert/encoder/layer_2/attention/self/query/kernel/adam_v',\n",
       " 'bert/encoder/layer_2/attention/self/value/bias',\n",
       " 'bert/encoder/layer_2/attention/self/value/bias/adam_m',\n",
       " 'bert/encoder/layer_2/attention/self/value/bias/adam_v',\n",
       " 'bert/encoder/layer_2/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_2/attention/self/value/kernel/adam_m',\n",
       " 'bert/encoder/layer_2/attention/self/value/kernel/adam_v',\n",
       " 'bert/encoder/layer_2/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_2/intermediate/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_2/intermediate/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_2/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_2/intermediate/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_2/intermediate/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_2/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_2/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_2/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_2/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_2/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_2/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_2/output/dense/bias',\n",
       " 'bert/encoder/layer_2/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_2/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_2/output/dense/kernel',\n",
       " 'bert/encoder/layer_2/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_2/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_3/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_3/attention/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_3/attention/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_3/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_3/attention/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_3/attention/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_3/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_3/attention/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_3/attention/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_3/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_3/attention/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_3/attention/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_3/attention/self/key/bias',\n",
       " 'bert/encoder/layer_3/attention/self/key/bias/adam_m',\n",
       " 'bert/encoder/layer_3/attention/self/key/bias/adam_v',\n",
       " 'bert/encoder/layer_3/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_3/attention/self/key/kernel/adam_m',\n",
       " 'bert/encoder/layer_3/attention/self/key/kernel/adam_v',\n",
       " 'bert/encoder/layer_3/attention/self/query/bias',\n",
       " 'bert/encoder/layer_3/attention/self/query/bias/adam_m',\n",
       " 'bert/encoder/layer_3/attention/self/query/bias/adam_v',\n",
       " 'bert/encoder/layer_3/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_3/attention/self/query/kernel/adam_m',\n",
       " 'bert/encoder/layer_3/attention/self/query/kernel/adam_v',\n",
       " 'bert/encoder/layer_3/attention/self/value/bias',\n",
       " 'bert/encoder/layer_3/attention/self/value/bias/adam_m',\n",
       " 'bert/encoder/layer_3/attention/self/value/bias/adam_v',\n",
       " 'bert/encoder/layer_3/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_3/attention/self/value/kernel/adam_m',\n",
       " 'bert/encoder/layer_3/attention/self/value/kernel/adam_v',\n",
       " 'bert/encoder/layer_3/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_3/intermediate/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_3/intermediate/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_3/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_3/intermediate/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_3/intermediate/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_3/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_3/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_3/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_3/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_3/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_3/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_3/output/dense/bias',\n",
       " 'bert/encoder/layer_3/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_3/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_3/output/dense/kernel',\n",
       " 'bert/encoder/layer_3/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_3/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_4/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_4/attention/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_4/attention/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_4/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_4/attention/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_4/attention/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_4/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_4/attention/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_4/attention/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_4/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_4/attention/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_4/attention/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_4/attention/self/key/bias',\n",
       " 'bert/encoder/layer_4/attention/self/key/bias/adam_m',\n",
       " 'bert/encoder/layer_4/attention/self/key/bias/adam_v',\n",
       " 'bert/encoder/layer_4/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_4/attention/self/key/kernel/adam_m',\n",
       " 'bert/encoder/layer_4/attention/self/key/kernel/adam_v',\n",
       " 'bert/encoder/layer_4/attention/self/query/bias',\n",
       " 'bert/encoder/layer_4/attention/self/query/bias/adam_m',\n",
       " 'bert/encoder/layer_4/attention/self/query/bias/adam_v',\n",
       " 'bert/encoder/layer_4/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_4/attention/self/query/kernel/adam_m',\n",
       " 'bert/encoder/layer_4/attention/self/query/kernel/adam_v',\n",
       " 'bert/encoder/layer_4/attention/self/value/bias',\n",
       " 'bert/encoder/layer_4/attention/self/value/bias/adam_m',\n",
       " 'bert/encoder/layer_4/attention/self/value/bias/adam_v',\n",
       " 'bert/encoder/layer_4/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_4/attention/self/value/kernel/adam_m',\n",
       " 'bert/encoder/layer_4/attention/self/value/kernel/adam_v',\n",
       " 'bert/encoder/layer_4/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_4/intermediate/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_4/intermediate/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_4/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_4/intermediate/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_4/intermediate/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_4/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_4/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_4/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_4/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_4/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_4/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_4/output/dense/bias',\n",
       " 'bert/encoder/layer_4/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_4/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_4/output/dense/kernel',\n",
       " 'bert/encoder/layer_4/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_4/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_5/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_5/attention/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_5/attention/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_5/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_5/attention/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_5/attention/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_5/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_5/attention/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_5/attention/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_5/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_5/attention/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_5/attention/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_5/attention/self/key/bias',\n",
       " 'bert/encoder/layer_5/attention/self/key/bias/adam_m',\n",
       " 'bert/encoder/layer_5/attention/self/key/bias/adam_v',\n",
       " 'bert/encoder/layer_5/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_5/attention/self/key/kernel/adam_m',\n",
       " 'bert/encoder/layer_5/attention/self/key/kernel/adam_v',\n",
       " 'bert/encoder/layer_5/attention/self/query/bias',\n",
       " 'bert/encoder/layer_5/attention/self/query/bias/adam_m',\n",
       " 'bert/encoder/layer_5/attention/self/query/bias/adam_v',\n",
       " 'bert/encoder/layer_5/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_5/attention/self/query/kernel/adam_m',\n",
       " 'bert/encoder/layer_5/attention/self/query/kernel/adam_v',\n",
       " 'bert/encoder/layer_5/attention/self/value/bias',\n",
       " 'bert/encoder/layer_5/attention/self/value/bias/adam_m',\n",
       " 'bert/encoder/layer_5/attention/self/value/bias/adam_v',\n",
       " 'bert/encoder/layer_5/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_5/attention/self/value/kernel/adam_m',\n",
       " 'bert/encoder/layer_5/attention/self/value/kernel/adam_v',\n",
       " 'bert/encoder/layer_5/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_5/intermediate/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_5/intermediate/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_5/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_5/intermediate/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_5/intermediate/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_5/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_5/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_5/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_5/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_5/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_5/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_5/output/dense/bias',\n",
       " 'bert/encoder/layer_5/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_5/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_5/output/dense/kernel',\n",
       " 'bert/encoder/layer_5/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_5/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_6/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_6/attention/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_6/attention/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_6/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_6/attention/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_6/attention/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_6/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_6/attention/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_6/attention/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_6/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_6/attention/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_6/attention/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_6/attention/self/key/bias',\n",
       " 'bert/encoder/layer_6/attention/self/key/bias/adam_m',\n",
       " 'bert/encoder/layer_6/attention/self/key/bias/adam_v',\n",
       " 'bert/encoder/layer_6/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_6/attention/self/key/kernel/adam_m',\n",
       " 'bert/encoder/layer_6/attention/self/key/kernel/adam_v',\n",
       " 'bert/encoder/layer_6/attention/self/query/bias',\n",
       " 'bert/encoder/layer_6/attention/self/query/bias/adam_m',\n",
       " 'bert/encoder/layer_6/attention/self/query/bias/adam_v',\n",
       " 'bert/encoder/layer_6/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_6/attention/self/query/kernel/adam_m',\n",
       " 'bert/encoder/layer_6/attention/self/query/kernel/adam_v',\n",
       " 'bert/encoder/layer_6/attention/self/value/bias',\n",
       " 'bert/encoder/layer_6/attention/self/value/bias/adam_m',\n",
       " 'bert/encoder/layer_6/attention/self/value/bias/adam_v',\n",
       " 'bert/encoder/layer_6/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_6/attention/self/value/kernel/adam_m',\n",
       " 'bert/encoder/layer_6/attention/self/value/kernel/adam_v',\n",
       " 'bert/encoder/layer_6/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_6/intermediate/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_6/intermediate/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_6/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_6/intermediate/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_6/intermediate/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_6/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_6/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_6/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_6/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_6/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_6/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_6/output/dense/bias',\n",
       " 'bert/encoder/layer_6/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_6/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_6/output/dense/kernel',\n",
       " 'bert/encoder/layer_6/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_6/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_7/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_7/attention/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_7/attention/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_7/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_7/attention/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_7/attention/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_7/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_7/attention/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_7/attention/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_7/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_7/attention/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_7/attention/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_7/attention/self/key/bias',\n",
       " 'bert/encoder/layer_7/attention/self/key/bias/adam_m',\n",
       " 'bert/encoder/layer_7/attention/self/key/bias/adam_v',\n",
       " 'bert/encoder/layer_7/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_7/attention/self/key/kernel/adam_m',\n",
       " 'bert/encoder/layer_7/attention/self/key/kernel/adam_v',\n",
       " 'bert/encoder/layer_7/attention/self/query/bias',\n",
       " 'bert/encoder/layer_7/attention/self/query/bias/adam_m',\n",
       " 'bert/encoder/layer_7/attention/self/query/bias/adam_v',\n",
       " 'bert/encoder/layer_7/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_7/attention/self/query/kernel/adam_m',\n",
       " 'bert/encoder/layer_7/attention/self/query/kernel/adam_v',\n",
       " 'bert/encoder/layer_7/attention/self/value/bias',\n",
       " 'bert/encoder/layer_7/attention/self/value/bias/adam_m',\n",
       " 'bert/encoder/layer_7/attention/self/value/bias/adam_v',\n",
       " 'bert/encoder/layer_7/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_7/attention/self/value/kernel/adam_m',\n",
       " 'bert/encoder/layer_7/attention/self/value/kernel/adam_v',\n",
       " 'bert/encoder/layer_7/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_7/intermediate/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_7/intermediate/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_7/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_7/intermediate/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_7/intermediate/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_7/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_7/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_7/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_7/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_7/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_7/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_7/output/dense/bias',\n",
       " 'bert/encoder/layer_7/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_7/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_7/output/dense/kernel',\n",
       " 'bert/encoder/layer_7/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_7/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_8/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_8/attention/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_8/attention/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_8/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_8/attention/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_8/attention/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_8/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_8/attention/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_8/attention/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_8/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_8/attention/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_8/attention/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_8/attention/self/key/bias',\n",
       " 'bert/encoder/layer_8/attention/self/key/bias/adam_m',\n",
       " 'bert/encoder/layer_8/attention/self/key/bias/adam_v',\n",
       " 'bert/encoder/layer_8/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_8/attention/self/key/kernel/adam_m',\n",
       " 'bert/encoder/layer_8/attention/self/key/kernel/adam_v',\n",
       " 'bert/encoder/layer_8/attention/self/query/bias',\n",
       " 'bert/encoder/layer_8/attention/self/query/bias/adam_m',\n",
       " 'bert/encoder/layer_8/attention/self/query/bias/adam_v',\n",
       " 'bert/encoder/layer_8/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_8/attention/self/query/kernel/adam_m',\n",
       " 'bert/encoder/layer_8/attention/self/query/kernel/adam_v',\n",
       " 'bert/encoder/layer_8/attention/self/value/bias',\n",
       " 'bert/encoder/layer_8/attention/self/value/bias/adam_m',\n",
       " 'bert/encoder/layer_8/attention/self/value/bias/adam_v',\n",
       " 'bert/encoder/layer_8/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_8/attention/self/value/kernel/adam_m',\n",
       " 'bert/encoder/layer_8/attention/self/value/kernel/adam_v',\n",
       " 'bert/encoder/layer_8/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_8/intermediate/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_8/intermediate/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_8/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_8/intermediate/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_8/intermediate/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_8/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_8/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_8/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_8/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_8/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_8/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_8/output/dense/bias',\n",
       " 'bert/encoder/layer_8/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_8/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_8/output/dense/kernel',\n",
       " 'bert/encoder/layer_8/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_8/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_9/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_9/attention/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_9/attention/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_9/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_9/attention/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_9/attention/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_9/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_9/attention/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_9/attention/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_9/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_9/attention/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_9/attention/output/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_9/attention/self/key/bias',\n",
       " 'bert/encoder/layer_9/attention/self/key/bias/adam_m',\n",
       " 'bert/encoder/layer_9/attention/self/key/bias/adam_v',\n",
       " 'bert/encoder/layer_9/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_9/attention/self/key/kernel/adam_m',\n",
       " 'bert/encoder/layer_9/attention/self/key/kernel/adam_v',\n",
       " 'bert/encoder/layer_9/attention/self/query/bias',\n",
       " 'bert/encoder/layer_9/attention/self/query/bias/adam_m',\n",
       " 'bert/encoder/layer_9/attention/self/query/bias/adam_v',\n",
       " 'bert/encoder/layer_9/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_9/attention/self/query/kernel/adam_m',\n",
       " 'bert/encoder/layer_9/attention/self/query/kernel/adam_v',\n",
       " 'bert/encoder/layer_9/attention/self/value/bias',\n",
       " 'bert/encoder/layer_9/attention/self/value/bias/adam_m',\n",
       " 'bert/encoder/layer_9/attention/self/value/bias/adam_v',\n",
       " 'bert/encoder/layer_9/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_9/attention/self/value/kernel/adam_m',\n",
       " 'bert/encoder/layer_9/attention/self/value/kernel/adam_v',\n",
       " 'bert/encoder/layer_9/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_9/intermediate/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_9/intermediate/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_9/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_9/intermediate/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_9/intermediate/dense/kernel/adam_v',\n",
       " 'bert/encoder/layer_9/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_9/output/LayerNorm/beta/adam_m',\n",
       " 'bert/encoder/layer_9/output/LayerNorm/beta/adam_v',\n",
       " 'bert/encoder/layer_9/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_9/output/LayerNorm/gamma/adam_m',\n",
       " 'bert/encoder/layer_9/output/LayerNorm/gamma/adam_v',\n",
       " 'bert/encoder/layer_9/output/dense/bias',\n",
       " 'bert/encoder/layer_9/output/dense/bias/adam_m',\n",
       " 'bert/encoder/layer_9/output/dense/bias/adam_v',\n",
       " 'bert/encoder/layer_9/output/dense/kernel',\n",
       " 'bert/encoder/layer_9/output/dense/kernel/adam_m',\n",
       " 'bert/encoder/layer_9/output/dense/kernel/adam_v',\n",
       " 'bert/pooler/dense/bias',\n",
       " 'bert/pooler/dense/bias/adam_m',\n",
       " 'bert/pooler/dense/bias/adam_v',\n",
       " 'bert/pooler/dense/kernel',\n",
       " 'bert/pooler/dense/kernel/adam_m',\n",
       " 'bert/pooler/dense/kernel/adam_v',\n",
       " 'global_step',\n",
       " 'output_bias',\n",
       " 'output_bias/adam_m',\n",
       " 'output_bias/adam_v',\n",
       " 'output_weights',\n",
       " 'output_weights/adam_m',\n",
       " 'output_weights/adam_v']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_variable_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01383783,  0.00570357, -0.04701683, ..., -0.04125093,\n",
       "        -0.04221822,  0.03177653],\n",
       "       [ 0.00646215, -0.04762628, -0.02844496, ...,  0.01216382,\n",
       "         0.00347079,  0.02835898],\n",
       "       [-0.05348697, -0.05752722,  0.01192973, ...,  0.0012023 ,\n",
       "        -0.03955814, -0.04730618],\n",
       "       ...,\n",
       "       [ 0.04078497,  0.03955465, -0.05358118, ...,  0.03683624,\n",
       "         0.02867581,  0.00650171],\n",
       "       [ 0.04629496, -0.06310652, -0.04017214, ...,  0.11711372,\n",
       "        -0.05839688,  0.01878156],\n",
       "       [ 0.00461925,  0.01636456, -0.04651957, ..., -0.0224819 ,\n",
       "        -0.04020511, -0.00791032]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_variable_value('bert/encoder/layer_9/attention/self/key/kernel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now for Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_html = \"\"\"\n",
    "  <span style=\"user-select:none\">\n",
    "    Layer: <select id=\"layer\"></select>\n",
    "    Attention: <select id=\"att_type\">\n",
    "      <option value=\"all\">All</option>\n",
    "      <option value=\"a\">Sentence A self-attention</option>\n",
    "      <option value=\"b\">Sentence B self-attention</option>\n",
    "      <option value=\"ab\">Sentence A -> Sentence B</option>\n",
    "      <option value=\"ba\">Sentence B -> Sentence A</option>\n",
    "    </select>\n",
    "  </span>\n",
    "  <div id='vis'></div>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "__location__ = os.path.realpath(\n",
    "    os.path.join(os.getcwd(), os.path.dirname(\"__file__\")))\n",
    "vis_js = open(os.path.join(__location__, 'attention.js')).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_att_mats(bert_model):\n",
    "    self_attentions = []\n",
    "    \n",
    "    layer_format = 'bert/encoder/layer_{}/attention/self/key/kernel'\n",
    "    for i in range(num_hidden_layers):\n",
    "        i_layer = layer_format.format(i)\n",
    "        self_attention = bert_model.get_variable_value(i_layer)\n",
    "        self_attentions.append(self_attention)\n",
    "    return self_attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_attentions = get_att_mats(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 768)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(self_attentions), len(self_attentions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 768)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_attentions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "_attn = self_attentions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0081959 ,  0.02625902, -0.01941409, ...,  0.02095003,\n",
       "        -0.053547  ,  0.00595329],\n",
       "       [-0.03752267, -0.06333707, -0.01727781, ..., -0.01776117,\n",
       "         0.02126005, -0.04799785],\n",
       "       [ 0.01843449,  0.01703105, -0.03340731, ..., -0.01087551,\n",
       "        -0.01802054,  0.02423437],\n",
       "       ...,\n",
       "       [ 0.0151049 , -0.01798486, -0.02701281, ...,  0.01855043,\n",
       "        -0.01006883, -0.00478966],\n",
       "       [-0.01491464, -0.04380539, -0.04236244, ..., -0.05464846,\n",
       "        -0.01638294, -0.00108903],\n",
       "       [-0.00956593,  0.01627923, -0.01053867, ...,  0.08322829,\n",
       "        -0.06601245, -0.00152366]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "require.config({\n",
       "  paths: {\n",
       "      d3: '//cdnjs.cloudflare.com/ajax/libs/d3/3.4.8/d3.min'\n",
       "  }\n",
       "});\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "require.config({\n",
    "  paths: {\n",
    "      d3: '//cdnjs.cloudflare.com/ajax/libs/d3/3.4.8/d3.min'\n",
    "  }\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A, B\n",
      "slice(0, 43, None) slice(43, 86, None)\n",
      "Layer ATTN\n",
      "(768, 768)\n",
      "[[ 0.0081959   0.02625902 -0.01941409 ...  0.02095003 -0.053547\n",
      "   0.00595329]\n",
      " [-0.03752267 -0.06333707 -0.01727781 ... -0.01776117  0.02126005\n",
      "  -0.04799785]\n",
      " [ 0.01843449  0.01703105 -0.03340731 ... -0.01087551 -0.01802054\n",
      "   0.02423437]\n",
      " ...\n",
      " [ 0.0151049  -0.01798486 -0.02701281 ...  0.01855043 -0.01006883\n",
      "  -0.00478966]\n",
      " [-0.01491464 -0.04380539 -0.04236244 ... -0.05464846 -0.01638294\n",
      "  -0.00108903]\n",
      " [-0.00956593  0.01627923 -0.01053867 ...  0.08322829 -0.06601245\n",
      "  -0.00152366]]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-00c45cb46cea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mattention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_attentions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Research/bert/visualization/attention.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(tokens_a, tokens_b, attn)\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0mself_att\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m   \u001b[0mattention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_att\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m   \u001b[0matt_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[0m_show_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matt_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Research/bert/visualization/attention.py\u001b[0m in \u001b[0;36m_get_attention\u001b[0;34m(tokens_a, tokens_b, attn)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mall_attns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_attn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Append AB->AB attention for layer, across all heads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0ma_attns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_attn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_a\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Append A->A attention for layer, across all heads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0mb_attns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_attn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_b\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Append B->B attention for layer, across all heads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0mab_attns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_attn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_b\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Append A->B attention for layer, across all heads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "attention.show(input_, input_, self_attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
